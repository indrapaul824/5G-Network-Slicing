{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using XGB - Base and Hyperparameter Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 9) (3000, 1)\n"
     ]
    }
   ],
   "source": [
    "x = pd.read_csv('../data/processed/x.csv')\n",
    "y = pd.read_csv('../data/processed/y.csv')\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration(sec)</th>\n",
       "      <th>Paket Loss Rate(Reliability)</th>\n",
       "      <th>Packet Delay Budget(Latency(ms))</th>\n",
       "      <th>Bandwidth(GHz)</th>\n",
       "      <th>Delay Rate(Mbps)</th>\n",
       "      <th>Speed(Mbps)</th>\n",
       "      <th>Jitter(ps)</th>\n",
       "      <th>User Device Type</th>\n",
       "      <th>Modulation Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.349610</td>\n",
       "      <td>0.510791</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.074074</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.880298</td>\n",
       "      <td>0.539568</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>0.939301</td>\n",
       "      <td>0.827338</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>0.275687</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.642252</td>\n",
       "      <td>0.366906</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Duration(sec)  Paket Loss Rate(Reliability)  \\\n",
       "0       1.000000                      1.000000   \n",
       "1       0.074074                      1.000000   \n",
       "2       0.333333                      0.000900   \n",
       "3       0.111111                      0.009901   \n",
       "4       0.000000                      0.000000   \n",
       "\n",
       "   Packet Delay Budget(Latency(ms))  Bandwidth(GHz)  Delay Rate(Mbps)  \\\n",
       "0                          1.000000        0.032258          1.000000   \n",
       "1                          0.122449        0.290323          0.081395   \n",
       "2                          0.918367        0.290323          0.034884   \n",
       "3                          0.224490        0.677419          0.034884   \n",
       "4                          0.979592        1.000000          0.081395   \n",
       "\n",
       "   Speed(Mbps)  Jitter(ps)  User Device Type  Modulation Type  \n",
       "0     0.349610    0.510791                 8                0  \n",
       "1     0.880298    0.539568                 8                0  \n",
       "2     0.939301    0.827338                 8                0  \n",
       "3     0.275687    1.000000                 8                0  \n",
       "4     0.642252    0.366906                 8                0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slice Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Slice Type\n",
       "0           1\n",
       "1           1\n",
       "2           1\n",
       "3           1\n",
       "4           1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train= (2100, 9)\n",
      "Shape of X_test= (900, 9)\n",
      "Shape of y_train= (2100, 1)\n",
      "Shape of y_test= (900, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = tts(x, y, test_size=0.30, random_state=10)\n",
    "print('Shape of X_train=',X_train.shape)\n",
    "print('Shape of X_test=',X_test.shape)\n",
    "print('Shape of y_train=',y_train.shape)\n",
    "print('Shape of y_test=',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:11:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\ttrain-mlogloss:4.25482\ttest-mlogloss:4.25340\n",
      "[1]\ttrain-mlogloss:4.16353\ttest-mlogloss:4.16103\n",
      "[2]\ttrain-mlogloss:4.08073\ttest-mlogloss:4.07741\n",
      "[3]\ttrain-mlogloss:4.00492\ttest-mlogloss:4.00090\n",
      "[4]\ttrain-mlogloss:3.93495\ttest-mlogloss:3.93024\n",
      "[5]\ttrain-mlogloss:3.86976\ttest-mlogloss:3.86476\n",
      "[6]\ttrain-mlogloss:3.80899\ttest-mlogloss:3.80378\n",
      "[7]\ttrain-mlogloss:3.75188\ttest-mlogloss:3.74640\n",
      "[8]\ttrain-mlogloss:3.69807\ttest-mlogloss:3.69255\n",
      "[9]\ttrain-mlogloss:3.64711\ttest-mlogloss:3.64169\n",
      "[10]\ttrain-mlogloss:3.59890\ttest-mlogloss:3.59354\n",
      "[11]\ttrain-mlogloss:3.55294\ttest-mlogloss:3.54772\n",
      "[12]\ttrain-mlogloss:3.50911\ttest-mlogloss:3.50418\n",
      "[13]\ttrain-mlogloss:3.46721\ttest-mlogloss:3.46277\n",
      "[14]\ttrain-mlogloss:3.42712\ttest-mlogloss:3.42312\n",
      "[15]\ttrain-mlogloss:3.38835\ttest-mlogloss:3.38478\n",
      "[16]\ttrain-mlogloss:3.35118\ttest-mlogloss:3.34803\n",
      "[17]\ttrain-mlogloss:3.31526\ttest-mlogloss:3.31268\n",
      "[18]\ttrain-mlogloss:3.28071\ttest-mlogloss:3.27874\n",
      "[19]\ttrain-mlogloss:3.24734\ttest-mlogloss:3.24601\n",
      "[20]\ttrain-mlogloss:3.21509\ttest-mlogloss:3.21432\n",
      "[21]\ttrain-mlogloss:3.18397\ttest-mlogloss:3.18377\n",
      "[22]\ttrain-mlogloss:3.15374\ttest-mlogloss:3.15414\n",
      "[23]\ttrain-mlogloss:3.12441\ttest-mlogloss:3.12529\n",
      "[24]\ttrain-mlogloss:3.09605\ttest-mlogloss:3.09748\n",
      "[25]\ttrain-mlogloss:3.06844\ttest-mlogloss:3.07035\n",
      "[26]\ttrain-mlogloss:3.04171\ttest-mlogloss:3.04392\n",
      "[27]\ttrain-mlogloss:3.01565\ttest-mlogloss:3.01832\n",
      "[28]\ttrain-mlogloss:2.99032\ttest-mlogloss:2.99333\n",
      "[29]\ttrain-mlogloss:2.96570\ttest-mlogloss:2.96901\n",
      "[30]\ttrain-mlogloss:2.94165\ttest-mlogloss:2.94509\n",
      "[31]\ttrain-mlogloss:2.91818\ttest-mlogloss:2.92195\n",
      "[32]\ttrain-mlogloss:2.89527\ttest-mlogloss:2.89926\n",
      "[33]\ttrain-mlogloss:2.87298\ttest-mlogloss:2.87726\n",
      "[34]\ttrain-mlogloss:2.85097\ttest-mlogloss:2.85570\n",
      "[35]\ttrain-mlogloss:2.82954\ttest-mlogloss:2.83460\n",
      "[36]\ttrain-mlogloss:2.80862\ttest-mlogloss:2.81389\n",
      "[37]\ttrain-mlogloss:2.78811\ttest-mlogloss:2.79379\n",
      "[38]\ttrain-mlogloss:2.76803\ttest-mlogloss:2.77404\n",
      "[39]\ttrain-mlogloss:2.74835\ttest-mlogloss:2.75480\n",
      "[40]\ttrain-mlogloss:2.72886\ttest-mlogloss:2.73596\n",
      "[41]\ttrain-mlogloss:2.70997\ttest-mlogloss:2.71751\n",
      "[42]\ttrain-mlogloss:2.69140\ttest-mlogloss:2.69938\n",
      "[43]\ttrain-mlogloss:2.67324\ttest-mlogloss:2.68187\n",
      "[44]\ttrain-mlogloss:2.65539\ttest-mlogloss:2.66435\n",
      "[45]\ttrain-mlogloss:2.63772\ttest-mlogloss:2.64727\n",
      "[46]\ttrain-mlogloss:2.62038\ttest-mlogloss:2.63095\n",
      "[47]\ttrain-mlogloss:2.60321\ttest-mlogloss:2.61464\n",
      "[48]\ttrain-mlogloss:2.58659\ttest-mlogloss:2.59873\n",
      "[49]\ttrain-mlogloss:2.57000\ttest-mlogloss:2.58298\n",
      "[50]\ttrain-mlogloss:2.55380\ttest-mlogloss:2.56771\n",
      "[51]\ttrain-mlogloss:2.53785\ttest-mlogloss:2.55240\n",
      "[52]\ttrain-mlogloss:2.52208\ttest-mlogloss:2.53735\n",
      "[53]\ttrain-mlogloss:2.50668\ttest-mlogloss:2.52283\n",
      "[54]\ttrain-mlogloss:2.49152\ttest-mlogloss:2.50829\n",
      "[55]\ttrain-mlogloss:2.47662\ttest-mlogloss:2.49415\n",
      "[56]\ttrain-mlogloss:2.46195\ttest-mlogloss:2.47996\n",
      "[57]\ttrain-mlogloss:2.44752\ttest-mlogloss:2.46608\n",
      "[58]\ttrain-mlogloss:2.43335\ttest-mlogloss:2.45243\n",
      "[59]\ttrain-mlogloss:2.41930\ttest-mlogloss:2.43928\n",
      "[60]\ttrain-mlogloss:2.40533\ttest-mlogloss:2.42608\n",
      "[61]\ttrain-mlogloss:2.39161\ttest-mlogloss:2.41324\n",
      "[62]\ttrain-mlogloss:2.37832\ttest-mlogloss:2.40021\n",
      "[63]\ttrain-mlogloss:2.36500\ttest-mlogloss:2.38772\n",
      "[64]\ttrain-mlogloss:2.35180\ttest-mlogloss:2.37552\n",
      "[65]\ttrain-mlogloss:2.33894\ttest-mlogloss:2.36308\n",
      "[66]\ttrain-mlogloss:2.32616\ttest-mlogloss:2.35107\n",
      "[67]\ttrain-mlogloss:2.31365\ttest-mlogloss:2.33912\n",
      "[68]\ttrain-mlogloss:2.30119\ttest-mlogloss:2.32726\n",
      "[69]\ttrain-mlogloss:2.28879\ttest-mlogloss:2.31595\n",
      "[70]\ttrain-mlogloss:2.27689\ttest-mlogloss:2.30425\n",
      "[71]\ttrain-mlogloss:2.26470\ttest-mlogloss:2.29318\n",
      "[72]\ttrain-mlogloss:2.25305\ttest-mlogloss:2.28179\n",
      "[73]\ttrain-mlogloss:2.24117\ttest-mlogloss:2.27118\n",
      "[74]\ttrain-mlogloss:2.22974\ttest-mlogloss:2.26012\n",
      "[75]\ttrain-mlogloss:2.21825\ttest-mlogloss:2.24950\n",
      "[76]\ttrain-mlogloss:2.20694\ttest-mlogloss:2.23921\n",
      "[77]\ttrain-mlogloss:2.19593\ttest-mlogloss:2.22855\n",
      "[78]\ttrain-mlogloss:2.18493\ttest-mlogloss:2.21827\n",
      "[79]\ttrain-mlogloss:2.17384\ttest-mlogloss:2.20840\n",
      "[80]\ttrain-mlogloss:2.16319\ttest-mlogloss:2.19822\n",
      "[81]\ttrain-mlogloss:2.15254\ttest-mlogloss:2.18818\n",
      "[82]\ttrain-mlogloss:2.14182\ttest-mlogloss:2.17876\n",
      "[83]\ttrain-mlogloss:2.13130\ttest-mlogloss:2.16915\n",
      "[84]\ttrain-mlogloss:2.12110\ttest-mlogloss:2.15936\n",
      "[85]\ttrain-mlogloss:2.11093\ttest-mlogloss:2.15011\n",
      "[86]\ttrain-mlogloss:2.10079\ttest-mlogloss:2.14074\n",
      "[87]\ttrain-mlogloss:2.09053\ttest-mlogloss:2.13170\n",
      "[88]\ttrain-mlogloss:2.08046\ttest-mlogloss:2.12282\n",
      "[89]\ttrain-mlogloss:2.07088\ttest-mlogloss:2.11358\n",
      "[90]\ttrain-mlogloss:2.06090\ttest-mlogloss:2.10491\n",
      "[91]\ttrain-mlogloss:2.05107\ttest-mlogloss:2.09644\n",
      "[92]\ttrain-mlogloss:2.04156\ttest-mlogloss:2.08763\n",
      "[93]\ttrain-mlogloss:2.03227\ttest-mlogloss:2.07878\n",
      "[94]\ttrain-mlogloss:2.02264\ttest-mlogloss:2.07039\n",
      "[95]\ttrain-mlogloss:2.01335\ttest-mlogloss:2.06203\n",
      "[96]\ttrain-mlogloss:2.00411\ttest-mlogloss:2.05396\n",
      "[97]\ttrain-mlogloss:1.99503\ttest-mlogloss:2.04567\n",
      "[98]\ttrain-mlogloss:1.98589\ttest-mlogloss:2.03762\n",
      "[99]\ttrain-mlogloss:1.97707\ttest-mlogloss:2.02950\n",
      "0.73\n",
      "0.7311111111111112\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "# specify parameters via map\n",
    "param = {'max_depth':20, 'eta':0.001, 'objective': 'multi:softmax', 'num_class':78, 'tree_method': 'gpu_hist' }\n",
    "num_round = 100\n",
    "watchlist = [(dtrain, 'train'), (dtest, 'test')]\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist)\n",
    "# make prediction\n",
    "preds_test = bst.predict(dtest)\n",
    "preds_train = bst.predict(dtrain)\n",
    "print(accuracy_score(y_train, preds_train))\n",
    "print(accuracy_score(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "dmatrix = xgb.DMatrix(x, label=y)\n",
    "# specify parameters via map\n",
    "param = {'max_depth':10, 'eta':0.001, 'objective': 'multi:softmax', 'num_class':78, 'tree_method': 'gpu_hist', }\n",
    "num_round = 100\n",
    "watchlist = [(dtrain, 'train'), (dtest, 'test')]\n",
    "bst = xgb.cv(params=param, dtrain=dtrain, nfold=10, metrics={'merror'}, as_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-merror-mean</th>\n",
       "      <th>train-merror-std</th>\n",
       "      <th>test-merror-mean</th>\n",
       "      <th>test-merror-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.285873</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>0.286667</td>\n",
       "      <td>0.026238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.285873</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>0.286667</td>\n",
       "      <td>0.026238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.285926</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>0.286667</td>\n",
       "      <td>0.026238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.286085</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>0.286190</td>\n",
       "      <td>0.025859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.286085</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>0.286190</td>\n",
       "      <td>0.025859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.286085</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>0.286190</td>\n",
       "      <td>0.025859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.286085</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>0.286190</td>\n",
       "      <td>0.025859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.286085</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>0.286190</td>\n",
       "      <td>0.025859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.286085</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>0.286190</td>\n",
       "      <td>0.025859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.286085</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>0.286190</td>\n",
       "      <td>0.025859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-merror-mean  train-merror-std  test-merror-mean  test-merror-std\n",
       "0           0.285873          0.003236          0.286667         0.026238\n",
       "1           0.285873          0.003236          0.286667         0.026238\n",
       "2           0.285926          0.003159          0.286667         0.026238\n",
       "3           0.286085          0.002965          0.286190         0.025859\n",
       "4           0.286085          0.002965          0.286190         0.025859\n",
       "5           0.286085          0.002965          0.286190         0.025859\n",
       "6           0.286085          0.002965          0.286190         0.025859\n",
       "7           0.286085          0.002965          0.286190         0.025859\n",
       "8           0.286085          0.002965          0.286190         0.025859\n",
       "9           0.286085          0.002965          0.286190         0.025859"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train= (2100, 9)\n",
      "Shape of X_test= (900, 9)\n",
      "Shape of y_train= (2100, 1)\n",
      "Shape of y_test= (900, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = tts(x, y, test_size=0.30, random_state=10)\n",
    "print('Shape of X_train=',X_train.shape)\n",
    "print('Shape of X_test=',X_test.shape)\n",
    "print('Shape of y_train=',y_train.shape)\n",
    "print('Shape of y_test=',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost hyper-parameter tuning\n",
    "def hyperParameterTuning(X_train, y_train):\n",
    "    param_tuning = {\n",
    "        'learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 7, 10, 15, 20],\n",
    "        'min_child_weight': [1, 3, 5, 7],\n",
    "        'subsample': [0.3, 0.5, 0.7],\n",
    "        'colsample_bytree': [0.3, 0.5, 0.7],\n",
    "        'n_estimators' : [100, 200, 500, 1000],\n",
    "        'objective': ['multi:softmax'],\n",
    "        'tree_method': ['gpu_hist']\n",
    "    }\n",
    "\n",
    "    xgb_model = XGBClassifier()\n",
    "\n",
    "    gsearch = GridSearchCV(estimator = xgb_model,\n",
    "                           param_grid = param_tuning,                        \n",
    "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
    "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
    "                           cv = 5,\n",
    "                           n_jobs = -1,\n",
    "                           verbose = 1)\n",
    "\n",
    "    gsearch.fit(X_train,y_train)\n",
    "\n",
    "    return gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\IPAnalysis-39\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\IPAnalysis-39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\IPAnalysis-39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 1,\n",
       " 'n_estimators': 500,\n",
       " 'objective': 'multi:softmax',\n",
       " 'subsample': 0.5,\n",
       " 'tree_method': 'gpu_hist'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperParameterTuning(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:13:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.7203333333333334\n"
     ]
    }
   ],
   "source": [
    "params = {'colsample_bytree': 0.7,\n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': 3,\n",
    "        'min_child_weight': 1,\n",
    "        'n_estimators': 500,\n",
    "        'objective': 'multi:softmax',\n",
    "        'subsample': 0.5,\n",
    "        'tree_method': 'gpu_hist'}\n",
    "\n",
    "# read in data\n",
    "dmatrix = xgb.DMatrix(x, label=y)\n",
    "num_round = 100\n",
    "bst = xgb.train(param, dmatrix)\n",
    "# make prediction\n",
    "preds = bst.predict(dmatrix)\n",
    "print(accuracy_score(y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f1af2f246daa54760268785cc37d3e760c0654a6af665420a07030e285142b3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('IPAnalysis-39': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
